{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c0c2f15-1a64-4b2b-8ca1-270f05aa24b9",
   "metadata": {},
   "source": [
    "# Python Text Analysis: Word Embeddings\n",
    "\n",
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "### Learning Objectives \n",
    "\n",
    "* Recognize differences between bag-of-words representations and word embeddings.\n",
    "* Learn how word embeddings capture the meaning of words.\n",
    "* Calculate cosine similarity to capture linguistic concepts.\n",
    "* Understand that word embeddings models can be biased, and develop approaches to uncover these biases.\n",
    "</div>\n",
    "\n",
    "### Icons Used in This Notebook\n",
    "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
    "ü•ä **Challenge**: Interactive excersise. We'll work through these in the workshop!<br>\n",
    "‚ö†Ô∏è **Warning:** Heads-up about tricky stuff or common mistakes.<br>\n",
    "üé¨ **Demo**: Showing off something more advanced ‚Äì so you know what Python can be used for!<br> \n",
    "\n",
    "### Sections\n",
    "1. [Understand Word Embeddings](#section1)\n",
    "2. [Word Similarity](#section2)\n",
    "3. [Word Analogy](#section3)\n",
    "4. [Bias in Word Embeddings](#section4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0add7f3-98c6-4248-bed3-1d4c5e0f6d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc6996",
   "metadata": {},
   "source": [
    "In Part 2, we have tried converting the text data to a numerical representation with Bags of Words (BoW) and beyond that, TF-IDF. These methods make heavy use of word frequency but not much of the relative positions between words, but there's still rich semantic and syntactic meanings left to be captured beyond independent frequencies of words. \n",
    "\n",
    "We need a more powerful tool that has the potential to represent rich semantics (and more) of our text data. In the final part of this series, we will dive into word embeddings, a method widely combined with more advanced Natural Language Processing (NLP) tasks. We'll make extensive use of the `gensim` package, which hosts a range of word embedding models, including `word2vec` and `glove`, the two models we'll explore today.\n",
    "\n",
    "<a id='section1'></a>\n",
    "\n",
    "# Understand Word Emebeddings \n",
    "\n",
    "As famously put by British Linguist J.R. Firth:\n",
    "\n",
    "> **You shall know a word by the company it keeps.**\n",
    "\n",
    "This quote sums it all for the essence of word embeddings, which take the numerical representation of text further to the next step. \n",
    "\n",
    "Recall from Part 2 that a BoW representation is a **sparse** matrix. Its dimension is determined by vocabulary size and the number of documents. Importantly, a sparse matrix like BoW is interpretable: the cell values refer to the count of a word in a document. Oftentimes the cell values are zeros: many words do not simply appear in a particular document. \n",
    "\n",
    "We can think of word embedding as a matrix likewise, but this time a **dense** matrix, where the cell values are real numbers. Word embeddings project a word's meaning onto a high-dimensional vector space, that's why it is also called **word vectors**. A word vector is essentially an array of real numbers, the length of which, as we'll see today, could be as low as 50, or as high as 300 (or even higher in Large Language Models). These real numbers do not make explicit sense to us, but this is not to say they are meaningless. The meanings of words, semantic or syntactic, are captured by the vector representation, which we will return to shortly.  \n",
    "\n",
    "BOW:\n",
    "- Sparse matrix\n",
    "- Dimension: $D$ x $V$, where rows are **D**ocuments and columns are words in the **V**ocabulary.\n",
    "- Interpretable: e.g., in a financial document, \"bank\" and \"banker\" could appear a lot of times but not \"bane\".\n",
    "\n",
    "<img src='../images/bow-illustration-2.png' alt=\"BoW\" width=\"500\">\n",
    "\n",
    "Word embeddings:\n",
    "- Dense matrix\n",
    "- Dimension: $V$ x $D$, where rows are **V**ocabulary and columns are vectors with dimension **D**.\n",
    "- Not immediately interpretable\n",
    "\n",
    "<img src='../images/bow-illustration-3.png' alt=\"BoW\" width=\"500\">\n",
    "\n",
    "Today, we are going to explore two widely used word embedding models, `word2vec` and `glove`. We will use the package `gensim` to access both models, so let's install gensim first.\n",
    "\n",
    "## Install `gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb1d3b7-bf13-4a9e-ba89-aed7eb0603d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run if you do not have gensim installed\n",
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390f01bd-e596-4d1a-89bf-147b3bdd3595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b2ac31-37a4-463d-8f49-bfd93c42904c",
   "metadata": {},
   "source": [
    "## `word2vec`\n",
    "\n",
    "Before diving into `word2vec`, let's talk a bit of history first. The idea of word vectors, i.e, projecting a word's meaning onto a vector space, has been around for a long time. The `word2vec` model, proposed by [Mikolov et al.](https://arxiv.org/abs/1310.4546) in 2013, introduces an efficient model of word embeddings, since then it has stimulated a new wave of research into this topic. \n",
    "\n",
    "The key question asked in this paper is: how do we go about learning a good vector representation from the data?\n",
    "\n",
    "Mikolov et al. proposed two approaches: the **continuous bag-of-words (CBOW)** and the **skip-gram (SG)**. Both are similar in that we use the vector representation of a token to try and predict what the nearby tokens are with a shallow neural network.   \n",
    "\n",
    "Take the following sentence from Merriam-Webster for example. If our target token is $w_t$, \"banks\", the context tokens would be the preceding tokens $w_{t-2}, w_{t-1}$ and the following ones $w_{t+1}, w_{t+2}$. This corresponds to a **window size** of 2: 2 words on either side of the target word. Similarly when we move onto the next tagret token, the context window (tokens underlined) moves as well.\n",
    "\n",
    "<img src='../images/target_word.png' alt=\"Trget word\" width=\"500\">\n",
    "\n",
    "In the continuous bag-of-words model, our goal is to predict the target token, given the context tokens. In the skip-gram model, the task is to predict the context tokens from the target token. This is the reverse of the continuous bag-of-words, and is a harder task, since we have to predict more from less information.\n",
    "\n",
    "<img src='../images/word2vec-model.png' alt=\"word2vec\" width=\"550\">\n",
    "\n",
    "**CBOW** (Left):\n",
    "- **Input**: context tokens\n",
    "- **Inner dimension**: embedding layer\n",
    "- **Output**: the target token\n",
    "\n",
    "**Skip-gram** (Right):\n",
    "- **Input**: the target token\n",
    "- **Inner dimension**: embedding layer\n",
    "- **Output**: context tokens.\n",
    "\n",
    "The above figure illustrates the direction of prediction. It also serves as a schematic representation of a neural network, i.e., the mechanics underlying the training of `word2vec`. The input and output are known to us, represented by **one-hot encodings** in Mikolov et al. The **hidden layer**, the inner dimension in-between the input and the output, is the vector representation that we are trying to find out. \n",
    "\n",
    "We won't go into the specifics of training but provide a brief idea of where does embedding come from. The `word2vec` model we will be interacting with today is **pre-trained**, meaning that the embeddings have already been trained on a large corpus (or a number of corpora). The pre-trained `word2vec` and `glove`, as well as other models, are available through `gensim`. \n",
    "\n",
    "Let's take a look at a few them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a320e320-8a4e-4cf9-8d14-378442fe5845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext-wiki-news-subwords-300\n",
      "conceptnet-numberbatch-17-06-300\n",
      "word2vec-ruscorpora-300\n",
      "word2vec-google-news-300\n",
      "glove-wiki-gigaword-50\n",
      "glove-wiki-gigaword-100\n",
      "glove-wiki-gigaword-200\n",
      "glove-wiki-gigaword-300\n",
      "glove-twitter-25\n",
      "glove-twitter-50\n",
      "glove-twitter-100\n",
      "glove-twitter-200\n",
      "__testing_word2vec-matrix-synopsis\n"
     ]
    }
   ],
   "source": [
    "# Get word embedding models\n",
    "gensim_models = list(api.info()['models'].keys())\n",
    "\n",
    "for model in gensim_models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c508421b-dd32-4173-8716-b47f89cd1a51",
   "metadata": {},
   "source": [
    "The one named `word2vec-google-news-300` is what we are looking for! The model name is usually formatted as `model-corpora-dimension`, so this is a `word2vec` model that is trained on Google News, and the embedding has 300 dimensions. \n",
    "\n",
    "We can retrieve this model in two ways:\n",
    "- Downloading it via `api.load()`\n",
    "- Downloading the model as a zip file beforehand and then loading it in with `KeyedVectors.load()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a28b0-475c-401a-a744-2d67a0c51d61",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------------------] 1.4% 23.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==------------------------------------------------] 4.5% 75.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===-----------------------------------------------] 7.7% 127.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====---------------------------------------------] 10.4% 172.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======--------------------------------------------] 13.3% 221.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========------------------------------------------] 16.4% 272.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========-----------------------------------------] 19.6% 325.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========---------------------------------------] 22.6% 376.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============--------------------------------------] 25.6% 425.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============------------------------------------] 28.6% 474.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===============-----------------------------------] 31.6% 525.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================---------------------------------] 34.5% 573.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================--------------------------------] 37.4% 622.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================------------------------------] 40.4% 671.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================-----------------------------] 43.3% 719.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================---------------------------] 46.4% 772.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================--------------------------] 49.3% 820.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================------------------------] 52.2% 867.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========================-----------------------] 55.0% 915.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================----------------------] 58.0% 964.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================--------------------] 61.0% 1014.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================------------------] 64.1% 1065.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================-----------------] 67.2% 1116.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================================---------------] 70.3% 1168.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================--------------] 73.5% 1221.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================================------------] 76.6% 1273.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================================-----------] 79.5% 1321.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================================---------] 82.7% 1374.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================================--------] 85.7% 1425.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================================------] 88.8% 1476.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================================-----] 91.2% 1517.2/1662.8MB downloaded"
     ]
    }
   ],
   "source": [
    "# Run the following line if your local machine has plenty of memory\n",
    "#wv = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b0380-54bf-47ba-aded-55e7b52c19d3",
   "metadata": {},
   "source": [
    "The parameter `binary` asks whether the model is in the binary format (indicated by the extension `.bin`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dced462a-e85a-4a0e-8698-66d49873fa4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/GoogleNews-vectors-negative300.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Alternatively, load the model in\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m wv \u001b[38;5;241m=\u001b[39m KeyedVectors\u001b[38;5;241m.\u001b[39mload_word2vec_format(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/GoogleNews-vectors-negative300.bin\u001b[39m\u001b[38;5;124m'\u001b[39m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gensim/models/keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1672\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_word2vec_format\u001b[39m(\n\u001b[1;32m   1674\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m, unicode_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1675\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, datatype\u001b[38;5;241m=\u001b[39mREAL, no_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1676\u001b[0m     ):\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m \n\u001b[1;32m   1679\u001b[0m \u001b[38;5;124;03m    Warnings\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[1;32m   1720\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39mfvocab, binary\u001b[38;5;241m=\u001b[39mbinary, encoding\u001b[38;5;241m=\u001b[39mencoding, unicode_errors\u001b[38;5;241m=\u001b[39municode_errors,\n\u001b[1;32m   1721\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit, datatype\u001b[38;5;241m=\u001b[39mdatatype, no_header\u001b[38;5;241m=\u001b[39mno_header,\n\u001b[1;32m   1722\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gensim/models/keyedvectors.py:2048\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   2045\u001b[0m             counts[word] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(count)\n\u001b[1;32m   2047\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading projection weights from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, fname)\n\u001b[0;32m-> 2048\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[1;32m   2049\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m no_header:\n\u001b[1;32m   2050\u001b[0m         \u001b[38;5;66;03m# deduce both vocab_size & vector_size from 1st pass over file\u001b[39;00m\n\u001b[1;32m   2051\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m binary:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/smart_open/smart_open_lib.py:188\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transport_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     transport_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 188\u001b[0m fobj \u001b[38;5;241m=\u001b[39m _shortcut_open(\n\u001b[1;32m    189\u001b[0m     uri,\n\u001b[1;32m    190\u001b[0m     mode,\n\u001b[1;32m    191\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    192\u001b[0m     buffering\u001b[38;5;241m=\u001b[39mbuffering,\n\u001b[1;32m    193\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    194\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    195\u001b[0m     newline\u001b[38;5;241m=\u001b[39mnewline,\n\u001b[1;32m    196\u001b[0m )\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fobj\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/smart_open/smart_open_lib.py:361\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    359\u001b[0m     open_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m errors\n\u001b[0;32m--> 361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _builtin_open(local_path, mode, buffering\u001b[38;5;241m=\u001b[39mbuffering, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopen_kwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/GoogleNews-vectors-negative300.bin'"
     ]
    }
   ],
   "source": [
    "# Alternatively, load the model in\n",
    "wv = KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925db1ea-6295-47b7-b6f2-45941c993e5c",
   "metadata": {},
   "source": [
    "Accessing the actual word vectors can be done by treating the word vector model as a dictionary. \n",
    "\n",
    "For example, let's take a look at the word vector for \"banana\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93fb02c-62ba-42f1-b6cb-b492bd21516e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wv['banana']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf15e57-7c49-4238-849b-90cc30813d2e",
   "metadata": {},
   "source": [
    "We can take a look at the shape of the \"banana\" vector. As promised, it is an 1-D array that holds 300 values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9c61de-8898-418b-a469-b25baa1e29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv['banana'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1de233-cef4-48c8-9f5d-57107a16d02d",
   "metadata": {},
   "source": [
    "These values appear to be random floats. However, now that the word has been transformed into a vector, we can more easily perform computations on it. \n",
    "\n",
    "Let's take a look at a few examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f917cd-f319-425d-8452-baa8c0598b82",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "\n",
    "# Word Similarity\n",
    "\n",
    "The first question we can ask is: What words are similar to \"bank\"? In vector space, we'd expect similar words to have vectors that are closer to each other.\n",
    "\n",
    "There are many metrics for measuring vector similarity, one of the most useful being [**cosine similarity**](https://en.wikipedia.org/wiki/Cosine_similarity). Cosine similarity ranges from 0 to 1, with orthogonal vectors having a cosine similarity of 0 and parallel vectors having a cosine similarity of 1.\n",
    "\n",
    "`gensim` provides a function called `most_similar()` that lets us find the words most similar to a queried word. The output is a tuple of the word and its cosine similarity to the queried word.\n",
    "\n",
    "Let's give it a shot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f6340f-cb0d-49f1-af0e-c584400f278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(['bank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133dd9f2-115e-4b75-9379-4f465e117b97",
   "metadata": {},
   "source": [
    "It looks like most similar vectors to \"bank\" are other financial terms! \n",
    "\n",
    "Recall that `word2vec` is trained to capture a word's meaning based on contextual information. These results pop up because these words commonly appear in similar contexts as the word \"bank\". \n",
    "\n",
    "In addition to querying the most similar words, we can also ask the model to return the cosine similarity between two words by calling the function `similarity()`\n",
    "\n",
    "Let's go ahead and check out the similarities between the following pairs of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee556605-b553-4ec3-b761-b83d737dce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bank with capitalized B\n",
    "wv.similarity('Bank', 'river')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd07f40-81bf-4aa8-826d-a06f723deae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the present participle of bank\n",
    "wv.similarity('banking', 'river')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df967c-8cc3-450a-b48e-1e0b76de2936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the word stem\n",
    "wv.similarity('bank', 'river')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97e2be-5998-466a-94e9-504281796768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bank in plural\n",
    "wv.similarity('banks', 'river')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217561a7-8dfe-4537-839d-0fa6b9063d9e",
   "metadata": {},
   "source": [
    "üîî **Question**: Why \"banks\" and \"river\" appear to have higher similarity than other pairs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec2123-05ec-46f8-b042-e761e72f1992",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 1: Dosen't Match\n",
    "\n",
    "We have a list of tuples for coffee-noun pairs. Let's find out which coffee drink is most commonly associated with the word \"coffee,\" and which one is not:\n",
    "\n",
    "- Complete the for loop to calculate the cosine similarity between each pair.\n",
    "\n",
    "Next, look up the documentation for the [`doesnt_match`](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#word2vec-demo) function. We will use it to identify the verb in the following list (one cell below) that does not seem to belong.\n",
    "\n",
    "- Use `doesnt_match` to find the verb that is unlikely to fit within the group.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671bda3d-8c55-44a1-9e32-8f7a6ef2a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_nouns = [\n",
    "    ('coffee', 'espresso'),\n",
    "    ('coffee', 'cappuccino'),\n",
    "    ('coffee', 'latte'),\n",
    "    ('coffee', 'americano'),\n",
    "    ('coffee', 'irish'),\n",
    "]\n",
    "\n",
    "# for w1, w2 in coffee_nouns:\n",
    "#     similarity = # YOUR CODE HERE\n",
    "#     print(f\"{w1}, {w2}, {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d860582-b5e9-43de-8e26-a40018d7ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w1, w2 in coffee_nouns:\n",
    "    similarity = wv.similarity(w1, w2)\n",
    "    print(f\"{w1}, {w2}, {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f86c65-c026-45f0-8e7c-8dbe088010b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_verbs = ['brew', 'drip', 'pour', 'make', 'grind', 'roast']\n",
    "\n",
    "# verb_dosent_match = # YOUR CODE HERE\n",
    "# verb_dosent_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e653f363-593a-43ce-bc5a-c463c7a6d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_dosent_match = wv.doesnt_match(coffee_verbs)\n",
    "verb_dosent_match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a73249a-b6c6-4a41-82c3-4fbc0947c26f",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "\n",
    "# Word Analogy\n",
    "\n",
    "One of the most famous usages of `word2vec` is via word analogies. For example:\n",
    "\n",
    "`man : king :: woman : queen`\n",
    "\n",
    "Oftentimes, word analogy like this is visualized with parallelogram, such as shown in the following figure, which is adapted from [Ethayarajh et al. (2019)](https://aclanthology.org/P19-1315.pdf). \n",
    "\n",
    "<img src='../images/word_analogy.png' alt=\"Word analogy\" width=\"450\">\n",
    "\n",
    "The upper side (difference between `man` and `woman`) should approximate the lower side (differ between `king` and `queen`); the vector difference represents the meanig of `female`. \n",
    "\n",
    "- $\\mathbf{V}_{\\text{man}} - \\mathbf{V}_{\\text{woman}} \\approx \\mathbf{V}_{\\text{king}} - \\mathbf{V}_{\\text{queen}}$\n",
    "\n",
    "Similarly, the left side (difference between `king` and `man`) should approximate the right side (differ between `queen` and `woman`); the vector difference represents the meaning of `royal`.\n",
    "\n",
    "- $\\mathbf{V}_{\\text{king}} - \\mathbf{V}_{\\text{man}} \\approx \\mathbf{V}_{\\text{queen}} - \\mathbf{V}_{\\text{woman}}$\n",
    "\n",
    "We can take either equation and rearrange it:\n",
    "\n",
    "- $\\mathbf{V}_{\\text{king}} - \\mathbf{V}_{\\text{man}} + \\mathbf{V}_{\\text{woman}} \\approx \\mathbf{V}_{\\text{Queen}}$\n",
    "\n",
    "If the vectors of `king`, `man`, and `woman` are known, by vector arithmatics we should be able to get a vector that approximates the meaning of `queen`. \n",
    "\n",
    "Let's implement it!\n",
    "\n",
    "‚ö†Ô∏è **Warning:** In all these operations, we set `norm=True`, and renormalize. That's because different vectors might be of different lengths, so the normalization puts everything on a common scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362bba64-01b0-4c1c-8e19-43365dd0834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate \"royal\" vector difference\n",
    "difference = wv.get_vector('king', norm=True) - wv.get_vector('man', norm=True) \n",
    "\n",
    "# Add on woman\n",
    "difference += wv.get_vector('woman', norm=True)\n",
    "\n",
    "# Renormalize vector\n",
    "difference = difference / np.linalg.norm(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d25a4d-5012-4035-8833-ce7f15afbed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the most similar vector?\n",
    "wv.most_similar(difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c755c-f22c-4e77-b8c2-c65a2f5a95a6",
   "metadata": {},
   "source": [
    "üîî **Question**: The word \"queen\" is the second most similar one. Why \"king\" has the highest similarity score?\n",
    "\n",
    "Carrying out these operations can be done in one swoop with the `most_similar` function. \n",
    "\n",
    "We pass in two arguments `positive` and `negative`, wherein `positive` holds the words that we want the output to be similar with, and `negative` the words we'd like the output to be dissimilar with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce536bb-fdd7-4afb-98be-3b30f92770e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(positive=['woman', 'king'], negative='man')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91687e2-62dc-4c20-adf7-75f2504df0ce",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 2: Woman is to Homemaker?\n",
    "\n",
    "[Bolukbasi et al. (2016)](https://arxiv.org/pdf/1607.06520) is a thought-provoking investigation of gender bias in word embeddings, and they primarily focus on word analogies, especially those that reveal gender stereotyping! Let run a couple examples discussed in the paper, using the `most_similiar` function we've just learned. \n",
    "\n",
    "The following code block contains a few examples we can pass to the `positive` argument: we want the output to be similar to, for example, `woman` and `chairman`, and in the meantime, we are also specificying that it should be dissimilar to `man`. We'll print the top result by indexing to the 0th item. \n",
    "\n",
    "Let's complete the following for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1653f664-5ab4-4f6e-b3fb-19c542674881",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pair = [['woman', 'chairman'],\n",
    "                 ['woman', 'doctor'], \n",
    "                 ['woman', 'computer_programmer']]\n",
    "negative_word = 'man'\n",
    "\n",
    "## YOUR CODE HERE\n",
    "# for example in positive_pair:\n",
    "#     result = ...\n",
    "#     print(f\"man is to {example[1]} as woman to {result[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b626f09-1a0c-4c60-8d3d-4147e8232c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in positive_pair:\n",
    "    result = wv.most_similar(positive=example, negative=negative_word)\n",
    "    print(f\"man is to {example[1]} as woman is to {result[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb6a4d3-ca70-4820-a570-198816a13f7f",
   "metadata": {},
   "source": [
    "üîî **Question**: What have you found? Are these results surprising?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85148bd-8d5c-4898-aceb-3185d132dcca",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "\n",
    "# Bias in Word Embeddings\n",
    "\n",
    "### `glove` \n",
    "\n",
    "Any forms of stereotyping is disturbing. Now that we've known gender bias is indeed present in the pre-trained embeddings. Let's take a closer look at it!\n",
    "\n",
    "We will switch gear to a smaller size embedding, i.e., pre-trained `glove`, starting from this section. Let's load it with the `api.load()` function. \n",
    "\n",
    "The model we load in is trained from Wikipedia and Gigaword (news data). Check out the [documentation](https://nlp.stanford.edu/projects/glove/) if you want to know further!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4676dca5-0be0-43dd-91ec-4ffe03928743",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = api.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e298be4-6521-4af7-82eb-e3a607ea5938",
   "metadata": {},
   "source": [
    "Let's double check the size of the embedding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a897d-1215-4e58-847e-6c6245ad6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove['banana'].size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56330365-6bcd-4fd5-b28a-0eb34ee66634",
   "metadata": {},
   "source": [
    "### Semantic Axis\n",
    "\n",
    "To investigate gender bias in word embeddings. We first need a vector representation that capture the concept of gender. The idea is to construct **a semantic axis** (or \"SemAxis\") of a concept. This concept is often complex, and cannot be simply denoted by a single word. And it is often fluid, meaning that its meaning spans form one end to the other. Once we've got the vector representation of this concept, we can project a list of terms that onto that axis, and see if each of the term is more aligned towars one end or the other of the concept. \n",
    "\n",
    "The methods of doing so comes from [An et al. 2018](https://aclanthology.org/P18-1228/). We will first need to come up with two lists of pole words, which are opposing to each other. \n",
    "\n",
    "- $\\mathbf{V}_{\\text{plus}} = \\{v_{1}^{+}, v_{2}^{+}, v_{3}^{+}, ..., v_{n}^{+}\\}$\n",
    "\n",
    "- $\\mathbf{V}_{\\text{minus}} = \\{v_{1}^{-}, v_{2}^{-}, v_{3}^{-}, ..., v_{n}^{-}\\}$\n",
    "\n",
    "We take the mean of each vector set to represent the core meaning of that set. \n",
    "\n",
    "- $\\mathbf{V}_{\\text{plus}} = \\frac{1}{n}\\sum_{1}^{n}v_{i}^{+}$\n",
    "\n",
    "- $\\mathbf{V}_{\\text{minus}} = \\frac{1}{n}\\sum_{1}^{n}v_{j}^{-}$\n",
    "\n",
    "Next we take the difference between the two means to represent the corresponding semantic axis. \n",
    "\n",
    "- $\\mathbf{V}_{\\text{axis}} = \\mathbf{V}_{\\text{plus}} - \\mathbf{V}_{\\text{minus}}$\n",
    "\n",
    "Projecting a specific term to the semantic axis is, as we've learned above, operationalized as taking the `cosine similarity` between the word's vector and the semantic axis vector. A positive value would indicate that the term is more closer to the $\\mathbf{V}_{\\text{plus}}$ end, and a negative value meaning proximity to the $\\mathbf{V}_{\\text{minus}}$ end. \n",
    "\n",
    "- $score(w) = cos(v_{w},  \\mathbf{V}_{\\text{axis}})$\n",
    "\n",
    "‚ö†Ô∏è **Warning:** A binary distinction of gender is a simplification of the diversity and complexity of gender identities. This method is limited, as it is only capable of constructing two polarities. Along the way, we'll discover how much stereotyping is encoded in it.\n",
    "\n",
    "## ü•ä Challenge 3: Construct a Semantic Axis\n",
    "\n",
    "Now it's your turn! We have two sets of pole words for \"female\" and \"male\". These are example words tested in Bolukbasi et al., 2016. We will get the embeddings for these words from glove to calculate the gender axis. \n",
    "\n",
    "The cell for the function `get_semaxis` provides some starting code. Complete the function. If everything runs, the embedding size of the semantic axis should be the same as the size of the input vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d3a8e-f605-4954-a6af-dc4d16d58b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two sets of pole words (examples from Bolukbasi et al., 2016)\n",
    "female = ['she', 'woman', 'female', 'daughter', 'mother', 'girl']\n",
    "male = ['he', 'man', 'male', 'son', 'father', 'boy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4d99b-0da1-4177-aa47-0db2e7a53a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_semaxis(list1, list2, model, embedding_size):\n",
    "#     '''Calculate the embedding of a semantic axis given two lists of pole words.'''\n",
    "\n",
    "#     # Step 1: Get the embeddings for terms in each list\n",
    "#     # vplus = ...\n",
    "#     # vminus = ...\n",
    "\n",
    "#     # Step 2: Calculate the mean embeddings for each list\n",
    "#     # vplus_mean = ...\n",
    "#     # vminus_mean = ...\n",
    "\n",
    "#     # Step 3: Get the difference between two means\n",
    "#     # sem_axis = ...\n",
    "\n",
    "#     # Sanity check\n",
    "#     assert sem_axis.size == embedding_size\n",
    "    \n",
    "#     return sem_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f616021-14b2-484f-b688-80400eb34382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semaxis(list1, list2, model, embedding_size):\n",
    "    '''Calculate the embedding of a semantic axis given two lists of pole words.'''\n",
    "\n",
    "    # STEP 1: Get the embeddings for terms in each list\n",
    "    vplus = [model[term] for term in list1]\n",
    "    vminus = [model[term] for term in list2]\n",
    "\n",
    "    # Step 2: Calculate the mean embeddings for each list\n",
    "    vplus_mean = np.mean(vplus, axis=0)\n",
    "    vminus_mean = np.mean(vminus, axis=0)\n",
    "\n",
    "    # Step 3: Get the difference between two means\n",
    "    sem_axis = vplus_mean - vminus_mean\n",
    "\n",
    "    # Sanity check\n",
    "    assert sem_axis.size == embedding_size\n",
    "    \n",
    "    return sem_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88257610-b8e7-4429-8d1f-dabe3de70891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plug in the gender lists to calculate the semantic axis for gender\n",
    "gender_axis = get_semaxis(list1=female, \n",
    "                          list2=male, \n",
    "                          model=glove, \n",
    "                          embedding_size=50)\n",
    "gender_axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748fa605-d07f-45ca-b786-795d034c6a61",
   "metadata": {},
   "source": [
    "We had the gender axis ready! The next step is to project a list of terms onto the gender axis. We can continue with the occupation terms we've tested previously. \n",
    "\n",
    "Before we go ahead to calculate the cosine similarity, let first rate the following occupation terms, use your intuition!\n",
    "\n",
    "The rating should be between $[-1, 1]$: the negative value means the term is closer to the male end and positive value to the female end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd47f71-7691-412d-be2e-046b0f13c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of occupations terms (examples taken from Bolukbaski et al., 2016)\n",
    "occupations = ['engineer',\n",
    "               'nurse',\n",
    "               'designer',\n",
    "               'receptionist',\n",
    "               'banker',\n",
    "               'librarian',\n",
    "               'architect',\n",
    "               'hairdresser',\n",
    "               'philosopher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab8481-40a5-4e7a-8ff1-4c0b086b5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate the following occupation terms\n",
    "occ_rating = {'engineer': -0.4,\n",
    "              'nurse': 0.6,\n",
    "              'designer':-0.1,\n",
    "              'receptionist':0.5,\n",
    "              'banker':-0.4,\n",
    "              'librarian': 0.5,\n",
    "              'architect': -0.4,\n",
    "              'hairdresser': 0.5,\n",
    "              'philosopher': -0.1\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9fed84-60fd-4d4b-9a07-658484c30aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between a given word and the axis\n",
    "def get_projection(word, model, axis):\n",
    "    '''Get the projection of a word onto a semantic axis'''\n",
    "    \n",
    "    word_norm = model[word] / np.linalg.norm(model[word])\n",
    "    axis_norm = axis / np.linalg.norm(axis)\n",
    "    projection = np.dot(word_norm, axis_norm) \n",
    "    \n",
    "    return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e537b5-165a-41be-8705-2f3d0092e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_projections = {word: get_projection(word, glove, gender_axis) for word in occupations}\n",
    "occ_projections "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c967ce2-1eac-483b-b46e-056bb0b8a8a9",
   "metadata": {},
   "source": [
    "## Visualize the Projection\n",
    "\n",
    "Now that we have calculated the projection of each occupation term onto the gender axis, let's plot these values to gain a more straightforward understanding of how much gender stereotyping is hidden in these terms.\n",
    "\n",
    "We will use a bar plot to visualize them, with the color of each bar corresponding to the proximity of a term to an end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0394ceb7-b50f-4d70-9443-0e255b4c4074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "\n",
    "def plot_semantic_axis(projections, title, xlab):\n",
    "    '''Return a horizontal bar plot of the projections.'''\n",
    "\n",
    "    # Sort the projections in descending order\n",
    "    projection_sorted = sorted(projections.items(), key=lambda term: term[1], reverse=True)\n",
    "\n",
    "    # Extract the terms\n",
    "    terms = [term_value[0] for term_value in projection_sorted]\n",
    "\n",
    "    # Extract corresponding values of projections\n",
    "    values = [term_value[1] for term_value in projection_sorted]\n",
    "\n",
    "    # Take the absolute values for gradient color fill\n",
    "    values_abs = np.abs(values)\n",
    "    norm = Normalize(vmin=min(values_abs), vmax=max(values_abs))\n",
    "    cmap = plt.get_cmap(\"YlOrBr\")  \n",
    "    colors = [cmap(norm(value)) for value in values_abs]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))  \n",
    "    plt.barh(terms, values, color=colors)\n",
    "    plt.grid(axis=\"x\", linestyle=\":\", alpha=0.5)\n",
    "    plt.xlim(-np.max(values_abs+0.05), np.max(values_abs+0.05))\n",
    "    plt.xlabel(xlab)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd4b50-e565-4e50-b063-7b88fba858e0",
   "metadata": {},
   "source": [
    "We will visualize the projections as well as your self-ratings together. \n",
    "\n",
    "üîî **Question**: Do you find the results surprising or expected? Let's pause for a minute to discuss why does steorotyping exist in word embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1286e06-9cf5-4bed-a755-987fbd53c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "title1 = 'Projections onto the gender axis'\n",
    "title2 = 'Self-rated projections onto the gender axis'\n",
    "xlab = 'Gender-stereotypical occpuation terms'\n",
    "\n",
    "plot_semantic_axis(occ_projections, title1, xlab)\n",
    "plot_semantic_axis(occ_rating, title2, xlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1490b4ca-41a9-4a0e-99d1-fb247f3927ff",
   "metadata": {},
   "source": [
    "## üé¨ **Demo**: The Class Axis\n",
    "\n",
    "In addition to projecting terms onto a single axis, we can also project terms onto two axes and plot the results on a scatter plot, where the coordinates correspond to projections onto the two axes.\n",
    "\n",
    "Social class is another dimension that has been frequently discussed in the literature. In this demo, we'll create a semantic axis for social class, using two sets of pole words representing the two ends of class, as described in [Kozlowski et al. 2019](https://journals.sagepub.com/doi/full/10.1177/0003122419877135).\n",
    "\n",
    "First, we'll project a list of sports terms onto both the gender and social class axes, similar to the method used in [Kozlowski et al. 2019](https://journals.sagepub.com/doi/full/10.1177/0003122419877135). We'll visualize the results on a scatter plot, with the x-axis representing gender and the y-axis representing social class. The coordinates of a term on this plot correspond to its projections onto these axes.\n",
    "\n",
    "Next, we'll repeat the process to visualize occupation terms, which will give us a rough idea of how much a term is biased towards either end of these two dimensions.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3597678-99ef-45b3-a78b-26b529db0acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two sets of pole words of social class (examples taken from Kozlowski et. al, 2019)\n",
    "poor = ['poor', 'poorer', 'poorest', 'poverty', 'inexpensive', 'impoverished', 'cheap']\n",
    "rich = ['rich', 'richer', 'richest', 'affluence', 'expensive', 'wealthy', 'luxury']\n",
    "\n",
    "class_axis = get_semaxis(list1=poor, \n",
    "                         list2=rich, \n",
    "                         model=glove,\n",
    "                         embedding_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a1ad74-c6a4-46ac-a7ce-78090d283f76",
   "metadata": {},
   "source": [
    "We will project sports terms onto the social class axis to see if some sports are more associated with the \"high\" society and others \"low\" soceity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b5d449-cca7-435a-9a33-65a622dcb340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of sports terms (examples taken from Kozlowski et. al, 2019)\n",
    "sports = ['camping', \n",
    "          'boxing', \n",
    "          'bowling', \n",
    "          'baseball', \n",
    "          'soccer', \n",
    "          'tennis', \n",
    "          'golf', \n",
    "          'basketball', \n",
    "          'skiing', \n",
    "          'sailing', \n",
    "          'volleyball']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56c3592-9760-4eb6-acda-bdc931c6284f",
   "metadata": {},
   "source": [
    "Next, let's use the `get_projection` function to calculate the cosine similarity between each sport term and the axis (gender and class). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e125157-e645-477a-8c8d-52932a68dba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_spt_class = {word: get_projection(word, glove, class_axis) for word in sports}\n",
    "proj_spt_gender = {word: get_projection(word, glove, gender_axis) for word in sports}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ec3d1-609a-4d2f-b9b3-25131a536e89",
   "metadata": {},
   "source": [
    "Finally, let's plot the results in a scatter plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a538e1-809f-49e5-94d3-c46888761229",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7))\n",
    "\n",
    "# Use scatter plot to visualize the results\n",
    "plt.scatter(list(proj_spt_gender.values()), \n",
    "            list(proj_spt_class.values()), \n",
    "            color='cornflowerblue',\n",
    "            s=75)\n",
    "\n",
    "# Add text label to each dot\n",
    "for term in sports:\n",
    "    plt.annotate(term, \n",
    "                 (proj_spt_gender[term], proj_spt_class[term]), \n",
    "                 fontsize=10)\n",
    "\n",
    "# Add more annotations to four corners of the plot\n",
    "plt.annotate('Male/High', (-0.48, -0.28), color='gray', horizontalalignment='left')\n",
    "plt.annotate('Female/High', (0.48, -0.28), color='gray', horizontalalignment='right')\n",
    "plt.annotate('Male/Low', (-0.48, 0.27), color='gray', horizontalalignment='left')\n",
    "plt.annotate('Female/Low', (0.48, 0.27), color='gray', horizontalalignment='right')\n",
    "\n",
    "# Add reference lines to each semantic axis\n",
    "plt.hlines(xmin=-1, xmax=1, y=0, color='lightcoral', linewidth=1, linestyle=':')\n",
    "plt.vlines(ymin=-1, ymax=1, x=0, color='lightcoral', linewidth=1, linestyle=':')\n",
    "\n",
    "# Other parameter settings\n",
    "plt.xlim(-0.5, 0.5)\n",
    "plt.ylim(-0.3, 0.3)\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.xlabel('Projection onto Gender')\n",
    "plt.ylabel('Projection onto Class')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b30b78-dd17-4bd5-9028-29e3f37cb963",
   "metadata": {},
   "source": [
    "üîî **Question**: Voil√†! Our scatter plot looks great. Let's take a minute to unpack the plot and discuss the following questions:\n",
    "- Which sport term is most biased towards male and which toward female?\n",
    "- Which sport seems to be gender-neutral?\n",
    "- Which sport term is most biased towards high social class, and which towards low social class?\n",
    "- Which sport seems to be neutral to class?\n",
    "\n",
    "Ok! Let's go back to occupation terms. We will first need to get the projections onto both axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaee050-9932-4aeb-a4db-87d46aeccac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_occ_gender = {word: get_projection(word, glove, gender_axis) for word in occupations}\n",
    "proj_occ_class = {word: get_projection(word, glove, class_axis) for word in occupations}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793cd949-b91e-498a-8b76-ce2368829f81",
   "metadata": {},
   "source": [
    "Next, let's visualize the results in a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66140280-3d5d-4aa9-9b76-781399f2c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7))\n",
    "\n",
    "# Use scatter plot to visualize the results\n",
    "plt.scatter(list(proj_occ_gender.values()), \n",
    "            list(proj_occ_class.values()), \n",
    "            color='tan', \n",
    "            s=75)\n",
    "\n",
    "# Add text label to each dot\n",
    "for term in occupations:\n",
    "    plt.annotate(term, \n",
    "                 (proj_occ_gender[term], proj_occ_class[term]), \n",
    "                 fontsize=10)\n",
    "\n",
    "# Add more annotations to four corners of the plot\n",
    "plt.annotate('Male/High', (-0.48, -0.48), color='gray', horizontalalignment='left')\n",
    "plt.annotate('Female/High', (0.48, -0.48), color='gray', horizontalalignment='right')\n",
    "plt.annotate('Male/Low', (-0.48, 0.45), color='gray', horizontalalignment='left')\n",
    "plt.annotate('Female/Low', (0.48, 0.45), color='gray', horizontalalignment='right')\n",
    "\n",
    "# Add reference lines to each semantic axis\n",
    "plt.hlines(xmin=-1, xmax=1, y=0, color='lightcoral', linewidth=1, linestyle=':')\n",
    "plt.vlines(ymin=-1, ymax=1, x=0, color='lightcoral', linewidth=1, linestyle=':')\n",
    "\n",
    "# Other parameter settings\n",
    "plt.xlim(-0.5, 0.5)\n",
    "plt.ylim(-0.5, 0.5)\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.xlabel('Projection onto Gender')\n",
    "plt.ylabel('Projection onto Class')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f93b7bf-f88e-460d-bcf7-f760597da95c",
   "metadata": {},
   "source": [
    "üîî **Question**: We've known how much each term is biased towards male/female. Let's focus on their projections onto the social class axis.\n",
    "- Which occuptation is most biased towards high social class, and which towards low social class?\n",
    "- Which occputation seems to be neutral to class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ec74c2-44d0-4061-888c-bb1d7e9e436a",
   "metadata": {},
   "source": [
    "We will wrap up this workshop with these two plots, and hopefully, they will leave you with some food for thought to further explore word embeddings. Constructing an axis of gender or social class has been widely researched, but with the tool of semantic axis, we can investigate much more. It is useful for capturing the abstract meaning of various notions, such as an axis of coldness, an axis of kindness, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc2acd5-fe77-4bee-916c-94d2443d3082",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## ‚ùó Key Points\n",
    "\n",
    "* Pre-trained word embeddings like `word2vec` and `glove` take contextual information into representations of words' meanings. \n",
    "* Similarities between words is conveniently reflected in cosine similarity. \n",
    "* We can explore biases in word embeddings with the methods of semantic axis.\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
